{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "Importing all needed dependencies to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612018493821
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import joblib\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core import Model, Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from impyute.imputation.cs import fast_knn\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "This dataset comes from the Diabetes and Digestive and Kidney Disease National Institutes. The purpose of this dataset is to diagnose whether or not a patient is diabetic, on the basis of certain diagnostic measures in the dataset. The selection of these instances from a larger database was subject to several restrictions. All patients are women from the Indian heritage of Pima, at least 21 years old. \n",
    "https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
    "\n",
    "Task\n",
    "Predict the \"Outcome\" column based on the input features, either the patient has diabetes or not.\n",
    "\n",
    "Reference: http://www.arogyaworld.org/wp-content/uploads/2010/10/ArogyaWorld_IndiaDiabetes_FactSheets_CGI2013_web.pdf\n",
    "\n",
    "The dataset has nine features as follow:\n",
    "- Pregnancies: Number pregnancy times (int).\n",
    "- Glucose: Plasma glucose concentration level (int).\n",
    "- BloodPressure: Diastolic blood pressure level in mm Hg(int).\n",
    "- SkinThickness: skinfold thickness in mm(int).\n",
    "- Insulin: two-hour serum insulin measured by mu U/ml(int).\n",
    "- BMI: Body mass index (float).\n",
    "- DiabetesPedigreeFunction: Diabetes pedigree function(float).\n",
    "- Age: age in years 21 and above(int).\n",
    "- Outcome: Target column 0 or 1, 0 = Not diabetes, 1 = diabetes(int)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'automl'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the registered dataset from workspace\n",
    "dataset = Dataset.get_by_name(ws, name='diabetes')\n",
    "\n",
    "# Convert the dataset to dataframe\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the first five records of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CPU cluster\n",
    "amlcompute_cluster_name = \"projectcluster\"\n",
    "\n",
    "# Verify if cluster does not exist otherwise use the existing one\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS12_V2',\n",
    "                                                           vm_priority = 'lowpriority', \n",
    "                                                           max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dataset.drop('Outcome', axis=1))\n",
    "scaler_features = scaler.transform(dataset.drop('Outcome', axis=1))\n",
    "df_feat = pd.DataFrame(scaler_features, columns=dataset.columns[:-1])\n",
    "\n",
    "# appending the outcome feature\n",
    "df_feat['Outcome'] = dataset['Outcome'].astype(int)\n",
    "dataset_updated = df_feat.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "Overview of the automl settings and configuration used for this experiment:\n",
    "\n",
    "- \"experiment_timeout_minutes\": set to 30 minutes. The experiment will timeout after that period to avoid wasting resources.\n",
    "- \"max_concurrent_iterations\": is set to 4. The max number of concurrent iterations to be run in parallel at the same time.\n",
    "- \"primary_metric\" : is set to 'accuracy', which is a sutible metric for classification problems.\n",
    "- \"n_cross_validations\": is set to 5, therefore the training and validation sets will be divided into five equal sets.\n",
    "- \"iterations\": the number of iterations for the experiment is set to 20. It's a reasonable number and would provide the intendable result for the given dataset.\n",
    "- compute_target: set to the project cluster to run the experiment.\n",
    "- task: set to 'classification' since our target to predict whether the patient has diabetes or not.\n",
    "- training_data: the loaded dataset for the project.\n",
    "- label_column_name: set to the result/target colunm in the dataset 'Outcome' (0 or 1).\n",
    "- enable_early_stopping: is enabled to terminate the experiment if the accuracy score is not showing improvement over time.\n",
    "- featurization = is set to 'auto', it's an indicator of whether implementing a featurization step to preprocess/clean the dataset automatically or not. In our case, the preprocessing was applied for the numerical columns which normally involve treating missing values, cluster distance, the weight of evidence...etc.\n",
    "- debug_log: errors will be logged into 'automl_errors.log'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Automl settings \n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 30,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"primary_metric\" : 'accuracy',\n",
    "    \"n_cross_validations\": 5,\n",
    "    \"iterations\": 24\n",
    "    \n",
    "}\n",
    "\n",
    "# Automl config \n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\n",
    "                             task = 'classification',\n",
    "                             training_data=dataset_updated,\n",
    "                             label_column_name='Outcome',\n",
    "                             enable_early_stopping= True,\n",
    "                             featurization = 'auto',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             **automl_settings\n",
    "                            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit experiment\n",
    "remote_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "The best model has resulted from the AutoML experiment from VotingEnsemble model. The Voting Ensemble model takes a majority vote of several algorithms which makes it surpass individual algorithms and minimize the bias. \n",
    "\n",
    "Use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "The cell below shows the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve and save best automl model\n",
    "best_model, model = remote_run.get_output()\n",
    "print(best_model)\n",
    "print(model.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "In the cell below, we have registered the model, created an inference config and deployed the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Registring the best model\n",
    "model = best_model.register_model(model_name='automl-best-model',model_path='outputs/model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# # create environment\n",
    "# environment = Environment(name=\"azure-env\")\n",
    "# conda_dep = CondaDependencies()\n",
    "\n",
    "# # Nedded packages and scripts\n",
    "# conda_dep.add_conda_package(\"pandas\")\n",
    "# conda_dep.add_conda_package(\"numpy\")\n",
    "# conda_dep.add_pip_package(\"scikit-learn\")\n",
    "# #conda_dep.add_conda_package(\"scikit-learn\")\n",
    "# conda_dep.add_pip_package(\"azureml-defaults\")\n",
    "\n",
    "# # Adding dependencies to the created environment\n",
    "# environment.python.conda_dependencies=conda_dep\n",
    "\n",
    "# Get automl environment with its dependencies\n",
    "environment = Environment.get(ws, \"AzureML-AutoML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(entry_script='scoring.py',\n",
    "                                   environment=environment)\n",
    "service_name = 'automl-deploy-1'\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name=service_name,\n",
    "                       models=[model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=deployment_config,\n",
    "                       overwrite=True\n",
    "                      )\n",
    "service.wait_for_deployment(show_output=True)\n",
    "\n",
    "scoring_uri = service.scoring_uri\n",
    "print(scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable app insights\n",
    "service.update(enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "In the cell below, we have sent a request to the web service to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL for the web service, should be similar to:\n",
    "#scoring_uri = 'http://0d469fee-33c0-4ce9-9dac-2767356110c9.southcentralus.azurecontainer.io/score'\n",
    "# If the service is authenticated, set the key or token\n",
    "#key = 'zuv0yY9prOPHFssuYSFWDJPhnVMxgJqG'\n",
    "#two set of data to score, so we get two results back\n",
    "data = {\"data\": [{\"Pregnancies\": 6, \n",
    "     \"Glucose\": 148, \n",
    "     \"BloodPressure\": 72, \n",
    "     \"SkinThickness\": 35, \n",
    "     \"Insulin\": 0, \n",
    "     \"BMI\": 33.5, \n",
    "     \"DiabetesPedigreeFunction\": 0.627, \n",
    "     \"Age\": 50},\n",
    "\n",
    "    {\"Pregnancies\": 1, \n",
    "     \"Glucose\": 85, \n",
    "     \"BloodPressure\": 66, \n",
    "     \"SkinThickness\": 29, \n",
    "     \"Insulin\": 20, \n",
    "     \"BMI\": 26.5, \n",
    "     \"DiabetesPedigreeFunction\": 0.351, \n",
    "     \"Age\": 31},\n",
    "      ]}\n",
    "    \n",
    "# Convert to JSON string\n",
    "input_data = json.dumps(data)\n",
    "with open(\"data.json\", \"w\") as _f:\n",
    "    _f.write(input_data)\n",
    "\n",
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "# If authentication is enabled, set the authorization header\n",
    "#headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.json())\n",
    "print(\"Case 0: Not Diabetes, Case 1: Diabetes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data = [{\n",
    "           \"Pregnancies\": 6, \n",
    "             \"Glucose\": 148, \n",
    "             \"BloodPressure\": 72, \n",
    "             \"SkinThickness\": 35, \n",
    "             \"Insulin\": 0, \n",
    "             \"BMI\": 33.5, \n",
    "             \"DiabetesPedigreeFunction\": 0.627, \n",
    "             \"Age\": 50\n",
    "           },\n",
    "          {\n",
    "            \"Pregnancies\": 1, \n",
    "             \"Glucose\": 85, \n",
    "             \"BloodPressure\": 66, \n",
    "             \"SkinThickness\": 29, \n",
    "             \"Insulin\": 20, \n",
    "             \"BMI\": 26.5, \n",
    "             \"DiabetesPedigreeFunction\": 0.351, \n",
    "             \"Age\": 31\n",
    "          },\n",
    "      ]\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test using service instance\n",
    "input_data = json.dumps({\n",
    "    'data': data\n",
    "})\n",
    "\n",
    "output = service.run(input_data)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "logs = service.get_logs()\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
